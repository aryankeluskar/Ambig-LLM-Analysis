# Do LLMs Understand Ambiguity in Human Language?

Code for the paper: **Do LLMs Understand Ambiguity in Text?** A Case Study in Open-world Question Answering

## Abstract

Ambiguity in natural language poses significant challenges to Large Language Models (LLMs) used for open-domain question answering. LLMs often struggle with the inherent uncertainties of human communication, leading to misinterpretations, miscommunications, hallucinations, and biased responses. This significantly weakens their ability to be used for tasks like fact-checking, question answering, feature extraction, and sentiment analysis. Using open-domain question answering as a test case, we compare off-the-shelf and few-shot LLM performance, focusing on measuring the impact of explicit disambiguation strategies. 

## Research Poster

 <img src="./Aryan FURI Fall 2024 Poster.png"> 


## Contact

For any questions, comments, and feedback, contact Aryan Keluskar at akeluska@asu.edu

### File Naming Convention

<img src="./file_naming_system.png>
