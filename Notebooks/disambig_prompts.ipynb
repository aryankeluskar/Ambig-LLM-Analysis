{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(text1, text2, model=\"text-embedding-3-small\"):\n",
    "   text1 = str(text1).lower()\n",
    "   text2 = str(text2).lower()\n",
    "   embedding1 = get_embedding(text1, model)\n",
    "   embedding2 = get_embedding(text2, model)\n",
    "   return cosine_similarity([embedding1], [embedding2])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(text1, text2, model=\"text-embedding-3-small\"):\n",
    "   embedding1 = get_embedding(text1, model)\n",
    "   embedding2 = get_embedding(text2, model)\n",
    "   return client.embeddings.cosine_similarity(embedding1, embedding2).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "str(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'nq_id': '-2735858160795120633', 'nq_question': 'Where is the lowest elevation in the world?', 'nq_answer': ['Dead Sea'], 'ambig_questions': [{'question': 'Where is the lowest known point in the world?', 'answer': ['Challenger Deep']}, {'question': 'Where is the lowest elevation below sea level in the world?', 'answer': ['Dead Sea, Jordan']}]}, {'nq_id': '-5398436847463533808', 'nq_question': 'Who voices beast in beauty and the beast 2017?', 'nq_answer': ['Adam Mitchell', 'Dan Stevens'], 'ambig_questions': [{'question': 'Who voices old beast in beauty and the beast 2017?', 'answer': ['Daniel Jonathan Stevens', 'Dan Stevens']}, {'question': 'Who voices young beast in beauty and the beast 2017?', 'answer': ['Adam Mitchell']}]}, {'nq_id': '-2578020881292839975', 'nq_question': 'What season of blue bloods are we in?', 'nq_answer': ['eighth season'], 'ambig_questions': [{'question': 'What season of blue bloods are we in at the end of 2017?', 'answer': ['8']}, {'question': 'What season of blue bloods are we in at the end of 2016?', 'answer': ['7']}, {'question': 'What season of blue bloods are we in at the end of 2015?', 'answer': ['6']}]}, {'nq_id': '5330941236576658337', 'nq_question': 'How many types of mangoes are grown in india?', 'nq_answer': ['283'], 'ambig_questions': [{'question': 'How many total types of mangoes are grown in India?', 'answer': ['283']}, {'question': 'How many well known types of mangoes are grown in India?', 'answer': ['30']}]}, {'nq_id': '2783829821720859339', 'nq_question': 'Who turns out to be the mother in how i met your mother?', 'nq_answer': ['Tracy McConnell'], 'ambig_questions': [{'question': 'Who turned out to be the mother in how i met your mother?', 'answer': ['Tracy Mosby (n√©e McConnell)']}, {'question': 'Who is the actress of the mother in how i met your mother?', 'answer': ['Cristin Milioti']}]}, {'nq_id': '6933855891752284994', 'nq_question': 'When did they stop making pennies in canada?', 'nq_answer': ['May 2012'], 'ambig_questions': [{'question': 'When did they last make pennies in canada?', 'answer': ['May 4, 2012', 'the morning of May 4, 2012', 'morning of May 4, 2012']}, {'question': 'When did they start melting pennies in circulation in canada?', 'answer': ['February 4, 2013']}]}, {'nq_id': '-964941354990822170', 'nq_question': 'Who is the president of south africa now?', 'nq_answer': ['Jacob Zuma'], 'ambig_questions': [{'question': 'Who is the president of south africa who first took office in 2009?', 'answer': ['JZ', 'Msholozi', 'Jacob Gedleyihlekisa Zuma', 'Jacob Zuma']}, {'question': 'Who is the president of south africa who first took office in 2008?', 'answer': ['Kgalema Petrus Motlanthe', 'Kgalema Motlanthe']}, {'question': 'Who is the president of south africa who first took office in 1999?', 'answer': ['Thabo Mvuyelwa Mbeki', 'Thabo Mbeki']}]}, {'nq_id': '-7922553386334138219', 'nq_question': 'What is the definition of low birth weight?', 'nq_answer': ['2,499 g or less'], 'ambig_questions': [{'question': 'What is the definition of a low birth weight baby?', 'answer': ['infant under 2,499 g']}, {'question': 'What is the definition of very low birth weight?', 'answer': ['infant under 1500 g']}, {'question': 'What is the definition of extremely low birth weight?', 'answer': ['infant under 1000 g']}]}, {'nq_id': '-2892210906132123257', 'nq_question': 'When did they put gates on downing street?', 'nq_answer': ['1989'], 'ambig_questions': [{'question': \"When did they put barriers on downing street at the St James's Park end of the street?\", 'answer': ['11 November 1920']}, {'question': 'When did they put a wooden barricade on downing street at the end of the street?', 'answer': ['26 November 1920']}, {'question': 'When did they put metal barriers on downing street at the end of the street?', 'answer': ['1973']}, {'question': 'When did they put a semi-permanent barrier on downing street between the pavement and carriageway on the Foreign Office side?', 'answer': ['1974']}, {'question': 'When did they put railings and a demountable gate on downing street?', 'answer': ['1982']}, {'question': 'When did they put black steel gates on downing street?', 'answer': ['1989']}]}, {'nq_id': '261255046711108270', 'nq_question': 'How old was mary queen of scots when she took the throne?', 'nq_answer': ['sixteen'], 'ambig_questions': [{'question': 'How old was mary queen of scots when she took the throne of Scotland?', 'answer': ['six days old']}, {'question': 'How old was mary queen of scots when she took the throne as queen consort of France?', 'answer': ['sixteen-year-old', 'sixteen']}]}, {'nq_id': '4884814654570325161', 'nq_question': 'Who wrote a diary about the great fire of london?', 'nq_answer': ['Samuel Pepys'], 'ambig_questions': [{'question': 'Who wrote the more well known diary about the great fire of london?', 'answer': ['Samuel Pepys']}, {'question': 'Who wrote the more lesser known diary about the great fire of london?', 'answer': ['John Evelyn']}]}, {'nq_id': '846559100871689657', 'nq_question': 'Who wrote the new york state constitution of 1777?', 'nq_answer': ['Robert R. Livingston', 'John Jay', 'Gouverneur Morris'], 'ambig_questions': [{'question': 'Which Chancellor wrote the new york state constitution of 1777?', 'answer': ['Robert R. Livingston']}, {'question': 'Which Gouverneur wrote the new york state constitution of 1777?', 'answer': ['Gouverneur Morris']}, {'question': 'Which Chief Justice wrote the new york state constitution of 1777?', 'answer': ['John Jay']}]}, {'nq_id': '-3793264343785361305', 'nq_question': 'Where does christina yang go in season 9?', 'nq_answer': ['Minnesota'], 'ambig_questions': [{'question': \"Where does Cristina Yang go to take up her fellowship in season 9 of Grey's Anatomy?\", 'answer': ['Rochester, Minnesota']}, {'question': \"Where does Cristina Yang go after the death of Doctor Thomas in season 9 of Grey's Anatomy?\", 'answer': ['Seattle, Washington']}]}, {'nq_id': '4294426664193526321', 'nq_question': 'Where did they film return of the jedi endor?', 'nq_answer': ['Del Norte County , CA'], 'ambig_questions': [{'question': 'Where did they film most of the return of the jedi endor scenes?', 'answer': ['Smith River, California', 'private logging company land']}, {'question': 'Where did they film most of the return of the jedi endor speeder chase scene?', 'answer': ['near the \"Avenue of the Giants\" in Humboldt Redwoods State Park', 'Chetham Grove section of Grizzly Creek Redwoods State Park']}]}, {'nq_id': '-5590188699529205461', 'nq_question': \"Who is jason's real mother on general hospital?\", 'nq_answer': ['Monica'], 'ambig_questions': [{'question': \"Which character is jason's real mother on general hospital?\", 'answer': ['Susan Moore']}, {'question': \"Which actress is jason's real mother on general hospital?\", 'answer': ['Gail Ramsey']}]}, {'nq_id': '4805212928450119213', 'nq_question': 'Who plays carrie on little house on the prairie?', 'nq_answer': ['Rachel Lindsay Rene Bush', 'Sidney Robyn Danae Bush'], 'ambig_questions': [{'question': 'Who plays carrie on the musical little house on the prairie?', 'answer': ['Carly Rose Sonenclar']}, {'question': 'Who plays carrie on the 1974 movie little house on the prairie?', 'answer': ['Rachel Lindsay Rene Bush', 'Sidney Robyn Danae Bush', 'Lindsay and Sidney Greenbush']}, {'question': 'Who plays carrie on the 1974 TV series little house on the prairie?', 'answer': ['Rachel Lindsay Rene Bush', 'Sidney Robyn Danae Bush', 'Lindsay and Sidney Greenbush']}, {'question': 'Who plays carrie on the 2005 TV series little house on the prairie?', 'answer': ['Erin Cottrell']}]}, {'nq_id': '-9174794329174540234', 'nq_question': 'When did apple tv 4th generation come out?', 'nq_answer': ['October 2015'], 'ambig_questions': [{'question': 'When did apple tv 4th generation announced?', 'answer': ['September 9, 2015']}, {'question': 'When did apple tv 4th generation start shipping?', 'answer': ['October 2015']}]}, {'nq_id': '4924936195381253041', 'nq_question': 'Who holds the most consecutive wins in mlb?', 'nq_answer': ['New York Giants'], 'ambig_questions': [{'question': 'What team holds the most consecutive wins in mlb?', 'answer': ['New York Giants']}, {'question': 'What team holds the most consecutive wins in the American league of mlb?', 'answer': ['Cleveland Indiands']}, {'question': 'What team holds the most consecutive wins only in playoffs of mlb?', 'answer': ['New York Yankees']}, {'question': 'What team holds the most consecutive wins in regular season and playoffs of mlb?', 'answer': ['Baltimore Orioles']}, {'question': 'What team holds the most consecutive wins in world series games of mlb?', 'answer': ['New York Yankees']}]}, {'nq_id': '-8901698354024630837', 'nq_question': 'How many episodes in season 2 of happy valley?', 'nq_answer': ['six'], 'ambig_questions': [{'question': 'How many episodes in season 2 of the Happy Valley tv series?', 'answer': ['6']}, {'question': 'How many episodes in series 1 and 2 of Happy Valley?', 'answer': ['12']}]}, {'nq_id': '-8434678371817632975', 'nq_question': 'Who was a at the beginning of pretty little liars?', 'nq_answer': ['Mona Vanderwaal ,'], 'ambig_questions': [{'question': 'Which character was a at the beginning of pretty little liars?', 'answer': ['Mona Vanderwaal', 'Mona']}, {'question': 'Which actress portrayed a at the beginning of pretty little liars?', 'answer': ['Janel Parrish']}]}, {'nq_id': '-3207884824372475669', 'nq_question': 'When did the us break away from england?', 'nq_answer': ['September 3 , 1783'], 'ambig_questions': [{'question': 'When did the us break away from england due to the adoption of the Declaration of Independence?', 'answer': ['July 4, 1776']}, {'question': 'When did the us break away from england due to the signing of the Treaty of Paris?', 'answer': ['September 3, 1783']}]}, {'nq_id': '-7688684232647280023', 'nq_question': 'Where is e3 2019 going to be held?', 'nq_answer': ['the Los Angeles Convention Center'], 'ambig_questions': [{'question': 'Where is the Electronic Entertainment Expo 2019 (E3 2019) to be held?', 'answer': ['Los Angeles, California', 'Los Angeles Convention Center']}, {'question': 'Where is the 2019 E3 BinckBank Cassic to be held?', 'answer': ['Belgium']}]}, {'nq_id': '-1534436996731657478', 'nq_question': \"Who wrote what you won't do for love?\", 'nq_answer': ['Bobby Caldwell'], 'ambig_questions': [{'question': \"Who wrote the novel what you won't do for love?\", 'answer': ['Alfons Kettner', 'Bobby Caldwell']}, {'question': \"Who wrote the song what you won't do for love?\", 'answer': ['Wendy Coakley-Thompson']}]}, {'nq_id': '-794169316362386713', 'nq_question': 'When did the european union start and for what main reason?', 'nq_answer': ['1 November 1993'], 'ambig_questions': [{'question': 'For what main reason did the european union start originally?', 'answer': ['Supranational union', 'supranational foundation', 'supranational foundation that would \"make war unthinkable and materially impossible\"and reinforce democracy amongst its members', 'multinational political union']}, {'question': 'According to Winston Churchill, the european union started originally to answer what call?', 'answer': ['call for a \"United States of Europe\"', '\"United States of Europe\"']}, {'question': 'When did the Maastricht Treaty start the european union?', 'answer': ['1992', '7 February 1992']}, {'question': 'When did the european union start indicated by creation of a common currency?', 'answer': ['1 January', '1999']}]}, {'nq_id': '-846321928275937158', 'nq_question': 'The barkana waterfalls is located in which state?', 'nq_answer': ['state of Karnataka , India'], 'ambig_questions': [{'question': 'What is the current name of the state where barkana waterfalls is located?', 'answer': ['Karnataka']}, {'question': 'What is the former name of the state where barkana waterfalls is located?', 'answer': ['State of Mysore']}]}, {'nq_id': '-3646009549730386860', 'nq_question': 'Who sings the only fools and horses theme?', 'nq_answer': ['John Sullivan'], 'ambig_questions': [{'question': 'Who sings the only Fools and Horses opening theme?', 'answer': ['John Sullivan']}, {'question': 'Who sings in the only Fools and Horses closing theme in the 1989 episode \"The Jolly Boys\\' Outing\"?', 'answer': ['Chas & Dave']}]}, {'nq_id': '-2742008795878689291', 'nq_question': 'Where did the roman spectators watch chariot races?', 'nq_answer': ['a circus'], 'ambig_questions': [{'question': 'What time of venue did the roman spectators watch chariot races?', 'answer': ['Roman circus', 'The Circus', 'circus']}, {'question': 'What specific place did the roman spectators most commonly watch chariot races?', 'answer': ['Circus Maximus', 'Circo Massimo']}]}, {'nq_id': '160462365288125381', 'nq_question': 'Who should be called the father of radio?', 'nq_answer': ['Lee de Forest'], 'ambig_questions': [{'question': 'Who should be called the father of radio, according to their own opinion?', 'answer': ['Forest', 'Lee de Forest']}, {'question': 'Who should be called the father of radio based on their research pioneering the invention of radio?', 'answer': ['Guglielmo Marconi', 'Guglielmo Marconi and Jagdish Chandra Bose', 'Jagdish Chandra Bose']}, {'question': 'Who should be called the father of radio based on radio broadcasting?', 'answer': ['Reginald Fessenden', 'Reginald Fessenden and David Sarnoff', 'David Sarnoff']}, {'question': 'Who should be called the father of radio because of his role in operating an FM Station?', 'answer': ['Armstrong', 'Edwin H. Armstrong']}]}, {'nq_id': '3319993667507902552', 'nq_question': 'Who has won the most little league world series?', 'nq_answer': ['Taiwan'], 'ambig_questions': [{'question': 'Who is the country that has won the most little league world series?', 'answer': ['Taiwan']}, {'question': 'Who is the state that has won the most little league world series?', 'answer': ['California']}]}, {'nq_id': '907287579079542483', 'nq_question': 'The sandhu bat island on which the statue of unity is to be built is located on which river?', 'nq_answer': ['Narmada River'], 'ambig_questions': [{'question': 'The sandhu bat island on which the statue of unity is to be built is located by which river?', 'answer': ['Narmada river', 'Narmada']}, {'question': 'The sandhu bat island on which the statue of unity is to be built is located on an artificial lake formed by what barrier?', 'answer': ['Garudeshwar weir']}]}]\n",
      "What location holds the lowest elevation in the world?\n",
      "{'data_id': '-2735858160795120633', 'ambig_question': 'Where is the lowest elevation in the world?', 'ambig_prompt_response': 'The Dead Sea.', 'disambig_question': 'What location holds the lowest elevation in the world?', 'disambig_prompt_response': 'The Dead Sea.', 'ground_truth': ['Dead Sea'], 'question_distance': 0.9352477559694059, 'answer_distance': 1.0, 'ambig_answer_distance': 0.8420445680092311, 'disambig_answer_distance': 0.8420445680092311}\n",
      "What actor voices the Beast in Beauty and the Beast 2017?\n",
      "{'data_id': '-5398436847463533808', 'ambig_question': 'Who voices beast in beauty and the beast 2017?', 'ambig_prompt_response': 'Dan Stevens', 'disambig_question': 'What actor voices the Beast in Beauty and the Beast 2017?', 'disambig_prompt_response': 'Dan Stevens', 'ground_truth': ['Adam Mitchell', 'Dan Stevens'], 'question_distance': 0.9661953002536665, 'answer_distance': 1.0000000000000013, 'ambig_answer_distance': 1.0000000000000013, 'disambig_answer_distance': 1.0000000000000013}\n",
      "In what season of Blue Bloods are we currently in during 2018?\n",
      "{'data_id': '-2578020881292839975', 'ambig_question': 'What season of blue bloods are we in?', 'ambig_prompt_response': 'Season 14', 'disambig_question': 'In what season of Blue Bloods are we currently in during 2018?', 'disambig_prompt_response': 'Season 9', 'ground_truth': ['eighth season'], 'question_distance': 0.9226859531985051, 'answer_distance': 0.641846107304588, 'ambig_answer_distance': 0.5714999866594473, 'disambig_answer_distance': 0.6115357286715232}\n",
      "What is the number of different types of mangoes grown in India?\n",
      "{'data_id': '5330941236576658337', 'ambig_question': 'How many types of mangoes are grown in india?', 'ambig_prompt_response': 'Over 1,500 varieties.', 'disambig_question': 'What is the number of different types of mangoes grown in India?', 'disambig_prompt_response': 'Over 1,000 types.', 'ground_truth': ['283'], 'question_distance': 0.9461481833254914, 'answer_distance': 0.7727508110145581, 'ambig_answer_distance': 0.2443340486736475, 'disambig_answer_distance': 0.2923945976515391}\n",
      "What character is revealed to be the mother in \"How I Met Your Mother\"?\n",
      "{'data_id': '2783829821720859339', 'ambig_question': 'Who turns out to be the mother in how i met your mother?', 'ambig_prompt_response': 'Tracy McConnell.', 'disambig_question': 'What character is revealed to be the mother in \"How I Met Your Mother\"?', 'disambig_prompt_response': 'Tracy McConnell.', 'ground_truth': ['Tracy McConnell'], 'question_distance': 0.9113130207604255, 'answer_distance': 1.0000000000000007, 'ambig_answer_distance': 0.9569594774349257, 'disambig_answer_distance': 0.9569594774349257}\n",
      "In what year did Canada stop making pennies?\n",
      "{'data_id': '6933855891752284994', 'ambig_question': 'When did they stop making pennies in canada?', 'ambig_prompt_response': '2012', 'disambig_question': 'In what year did Canada stop making pennies?', 'disambig_prompt_response': '2012', 'ground_truth': ['May 2012'], 'question_distance': 0.9391136973930557, 'answer_distance': 0.9999999999999996, 'ambig_answer_distance': 0.6640836704299936, 'disambig_answer_distance': 0.6640836704299936}\n",
      "What person is the president of South Africa now?\n",
      "{'data_id': '-964941354990822170', 'ambig_question': 'Who is the president of south africa now?', 'ambig_prompt_response': 'Cyril Ramaphosa', 'disambig_question': 'What person is the president of South Africa now?', 'disambig_prompt_response': 'Cyril Ramaphosa.', 'ground_truth': ['Jacob Zuma'], 'question_distance': 0.9831670280463218, 'answer_distance': 0.9575878393434245, 'ambig_answer_distance': 0.6315484564344197, 'disambig_answer_distance': 0.6233082116477342}\n",
      "What measurement is used to define low birth weight?\n",
      "{'data_id': '-7922553386334138219', 'ambig_question': 'What is the definition of low birth weight?', 'ambig_prompt_response': 'Less than 2,500 grams (5 pounds, 8 ounces).', 'disambig_question': 'What measurement is used to define low birth weight?', 'disambig_prompt_response': 'Less than 2,500 grams (5.5 pounds).', 'ground_truth': ['2,499 g or less'], 'question_distance': 0.8559347978087352, 'answer_distance': 0.9465198471984932, 'ambig_answer_distance': 0.6301554284450044, 'disambig_answer_distance': 0.6261593198182609}\n",
      "What timeframe did they put gates on Downing Street?\n",
      "{'data_id': '-2892210906132123257', 'ambig_question': 'When did they put gates on downing street?', 'ambig_prompt_response': '1989', 'disambig_question': 'What timeframe did they put gates on Downing Street?', 'disambig_prompt_response': '1989', 'ground_truth': ['1989'], 'question_distance': 0.9368009177499129, 'answer_distance': 1.0, 'ambig_answer_distance': 1.0, 'disambig_answer_distance': 1.0}\n",
      "What was the age of Mary Queen of Scots when she took the throne?\n",
      "{'data_id': '261255046711108270', 'ambig_question': 'How old was mary queen of scots when she took the throne?', 'ambig_prompt_response': 'Mary Queen of Scots was 6 days old when she took the throne.', 'disambig_question': 'What was the age of Mary Queen of Scots when she took the throne?', 'disambig_prompt_response': 'Six days old.', 'ground_truth': ['sixteen'], 'question_distance': 0.9705923917056328, 'answer_distance': 0.4176660294395183, 'ambig_answer_distance': 0.20164187285803, 'disambig_answer_distance': 0.3174435928922882}\n",
      "What person wrote a diary about the Great Fire of London?\n",
      "{'data_id': '4884814654570325161', 'ambig_question': 'Who wrote a diary about the great fire of london?', 'ambig_prompt_response': 'Samuel Pepys', 'disambig_question': 'What person wrote a diary about the Great Fire of London?', 'disambig_prompt_response': 'Samuel Pepys', 'ground_truth': ['Samuel Pepys'], 'question_distance': 0.9883213794282395, 'answer_distance': 1.0000000000000018, 'ambig_answer_distance': 1.0000000000000018, 'disambig_answer_distance': 1.0000000000000018}\n",
      "What person authored the New York State Constitution of 1777?\n",
      "{'data_id': '846559100871689657', 'ambig_question': 'Who wrote the new york state constitution of 1777?', 'ambig_prompt_response': 'John Jay', 'disambig_question': 'What person authored the New York State Constitution of 1777?', 'disambig_prompt_response': 'John Jay', 'ground_truth': ['Robert R. Livingston', 'John Jay', 'Gouverneur Morris'], 'question_distance': 0.9539790535916459, 'answer_distance': 0.9999992369393104, 'ambig_answer_distance': 0.999999167693598, 'disambig_answer_distance': 0.9999999999999997}\n",
      "What location does Christina Yang go to in season 9?\n",
      "{'data_id': '-3793264343785361305', 'ambig_question': 'Where does christina yang go in season 9?', 'ambig_prompt_response': 'Mayo Clinic', 'disambig_question': 'What location does Christina Yang go to in season 9?', 'disambig_prompt_response': 'Minnesota.', 'ground_truth': ['Minnesota'], 'question_distance': 0.9598930704253279, 'answer_distance': 0.3359799158632264, 'ambig_answer_distance': 0.34693200477774433, 'disambig_answer_distance': 0.9354703136369705}\n",
      "What location did they use to film the Endor scenes in \"Return of the Jedi\"?\n",
      "{'data_id': '4294426664193526321', 'ambig_question': 'Where did they film return of the jedi endor?', 'ambig_prompt_response': 'Redwood National and State Parks, California.', 'disambig_question': 'What location did they use to film the Endor scenes in \"Return of the Jedi\"?', 'disambig_prompt_response': 'Redwood National and State Parks, California.', 'ground_truth': ['Del Norte County , CA'], 'question_distance': 0.9196670878763518, 'answer_distance': 0.9999999999999996, 'ambig_answer_distance': 0.41358780546600904, 'disambig_answer_distance': 0.41358780546600904}\n",
      "What person is Jason's real mother on General Hospital?\n",
      "{'data_id': '-5590188699529205461', 'ambig_question': \"Who is jason's real mother on general hospital?\", 'ambig_prompt_response': 'Monica Quartermaine', 'disambig_question': \"What person is Jason's real mother on General Hospital?\", 'disambig_prompt_response': 'Susan Moore', 'ground_truth': ['Monica'], 'question_distance': 0.9924166671017725, 'answer_distance': 0.34033048886120276, 'ambig_answer_distance': 0.7462360684263212, 'disambig_answer_distance': 0.33222204364107055}\n",
      "What actress plays Carrie on Little House on the Prairie?\n",
      "{'data_id': '4805212928450119213', 'ambig_question': 'Who plays carrie on little house on the prairie?', 'ambig_prompt_response': 'Lindsay Greenbush', 'disambig_question': 'What actress plays Carrie on Little House on the Prairie?', 'disambig_prompt_response': 'Lindsay Greenbush', 'ground_truth': ['Rachel Lindsay Rene Bush', 'Sidney Robyn Danae Bush'], 'question_distance': 0.9783240432503146, 'answer_distance': 0.9999999999999996, 'ambig_answer_distance': 0.6591529178003955, 'disambig_answer_distance': 0.6591529178003955}\n",
      "What year did the Apple TV 4th generation come out? (Specify 2018 if needed)\n",
      "{'data_id': '-9174794329174540234', 'ambig_question': 'When did apple tv 4th generation come out?', 'ambig_prompt_response': 'October 30, 2015', 'disambig_question': 'What year did the Apple TV 4th generation come out? (Specify 2018 if needed)', 'disambig_prompt_response': '2015', 'ground_truth': ['October 2015'], 'question_distance': 0.8412909130196322, 'answer_distance': 0.6107359107045454, 'ambig_answer_distance': 0.8216142768574684, 'disambig_answer_distance': 0.71664523935644}\n",
      "What team holds the most consecutive wins in MLB?\n",
      "{'data_id': '4924936195381253041', 'ambig_question': 'Who holds the most consecutive wins in mlb?', 'ambig_prompt_response': 'New York Giants (1916)', 'disambig_question': 'What team holds the most consecutive wins in MLB?', 'disambig_prompt_response': 'New York Giants', 'ground_truth': ['New York Giants'], 'question_distance': 0.8662249500665447, 'answer_distance': 0.7705241782404361, 'ambig_answer_distance': 0.7705241782404361, 'disambig_answer_distance': 0.9999999999999989}\n",
      "In the year 2018, what is the number of episodes in season 2 of \"Happy Valley\"?\n",
      "{'data_id': '-8901698354024630837', 'ambig_question': 'How many episodes in season 2 of happy valley?', 'ambig_prompt_response': 'Six.', 'disambig_question': 'In the year 2018, what is the number of episodes in season 2 of \"Happy Valley\"?', 'disambig_prompt_response': '6', 'ground_truth': ['six'], 'question_distance': 0.9320330425711854, 'answer_distance': 0.6429479674450139, 'ambig_answer_distance': 0.765870185928943, 'disambig_answer_distance': 0.6310083346318558}\n",
      "What person was \"A\" at the beginning of Pretty Little Liars?\n",
      "{'data_id': '-8434678371817632975', 'ambig_question': 'Who was a at the beginning of pretty little liars?', 'ambig_prompt_response': 'Alison DiLaurentis', 'disambig_question': 'What person was \"A\" at the beginning of Pretty Little Liars?', 'disambig_prompt_response': 'Mona Vanderwaal', 'ground_truth': ['Mona Vanderwaal ,'], 'question_distance': 0.9310728382855189, 'answer_distance': 0.35138638431472385, 'ambig_answer_distance': 0.3492966308851985, 'disambig_answer_distance': 0.9520286899303271}\n",
      "What year did the US break away from England?\n",
      "{'data_id': '-3207884824372475669', 'ambig_question': 'When did the us break away from england?', 'ambig_prompt_response': '1776', 'disambig_question': 'What year did the US break away from England?', 'disambig_prompt_response': '1776', 'ground_truth': ['September 3 , 1783'], 'question_distance': 0.9750731789742406, 'answer_distance': 1.0000000000000009, 'ambig_answer_distance': 0.5557181337649113, 'disambig_answer_distance': 0.5557181337649113}\n",
      "What location is hosting E3 2019?\n",
      "{'data_id': '-7688684232647280023', 'ambig_question': 'Where is e3 2019 going to be held?', 'ambig_prompt_response': 'Los Angeles Convention Center.', 'disambig_question': 'What location is hosting E3 2019?', 'disambig_prompt_response': 'Los Angeles Convention Center.', 'ground_truth': ['the Los Angeles Convention Center'], 'question_distance': 0.878044518088738, 'answer_distance': 0.9999999999999992, 'ambig_answer_distance': 0.9280532483576625, 'disambig_answer_distance': 0.9280532483576625}\n",
      "What person wrote \"What You Won't Do for Love\"?\n",
      "{'data_id': '-1534436996731657478', 'ambig_question': \"Who wrote what you won't do for love?\", 'ambig_prompt_response': 'Bobby Caldwell', 'disambig_question': 'What person wrote \"What You Won\\'t Do for Love\"?', 'disambig_prompt_response': 'Bobby Caldwell', 'ground_truth': ['Bobby Caldwell'], 'question_distance': 0.8986760478542726, 'answer_distance': 1.0000000000000009, 'ambig_answer_distance': 1.0000000000000009, 'disambig_answer_distance': 1.0000000000000009}\n",
      "What timeframe did the European Union start in? What was the main reason for its founding?\n",
      "{'data_id': '-794169316362386713', 'ambig_question': 'When did the european union start and for what main reason?', 'ambig_prompt_response': '1958, economic integration.', 'disambig_question': 'What timeframe did the European Union start in? What was the main reason for its founding?', 'disambig_prompt_response': '1950s; To promote economic cooperation and prevent conflict in Europe.', 'ground_truth': ['1 November 1993'], 'question_distance': 0.864125369101133, 'answer_distance': 0.602484080493517, 'ambig_answer_distance': 0.38063746507508933, 'disambig_answer_distance': 0.28662523696336745}\n",
      "The Barkana Waterfalls is located in what state?\n",
      "{'data_id': '-846321928275937158', 'ambig_question': 'The barkana waterfalls is located in which state?', 'ambig_prompt_response': 'Karnataka', 'disambig_question': 'The Barkana Waterfalls is located in what state?', 'disambig_prompt_response': 'Karnataka', 'ground_truth': ['state of Karnataka , India'], 'question_distance': 0.982341381136898, 'answer_distance': 1.000000000000001, 'ambig_answer_distance': 0.8124835139406057, 'disambig_answer_distance': 0.8124507826456238}\n",
      "What person sings the \"Only Fools and Horses\" theme?\n",
      "{'data_id': '-3646009549730386860', 'ambig_question': 'Who sings the only fools and horses theme?', 'ambig_prompt_response': 'John Sullivan', 'disambig_question': 'What person sings the \"Only Fools and Horses\" theme?', 'disambig_prompt_response': 'John Sullivan', 'ground_truth': ['John Sullivan'], 'question_distance': 0.967601026207674, 'answer_distance': 0.999999266517406, 'ambig_answer_distance': 1.0000000000000007, 'disambig_answer_distance': 1.0000000000000007}\n",
      "What location did the Roman spectators use to watch chariot races?\n",
      "{'data_id': '-2742008795878689291', 'ambig_question': 'Where did the roman spectators watch chariot races?', 'ambig_prompt_response': 'Circus Maximus', 'disambig_question': 'What location did the Roman spectators use to watch chariot races?', 'disambig_prompt_response': 'Circus Maximus', 'ground_truth': ['a circus'], 'question_distance': 0.9543757418305681, 'answer_distance': 1.0000000000000002, 'ambig_answer_distance': 0.6754600935575907, 'disambig_answer_distance': 0.6754600935575907}\n",
      "What individual should be called the father of radio?\n",
      "{'data_id': '160462365288125381', 'ambig_question': 'Who should be called the father of radio?', 'ambig_prompt_response': 'Guglielmo Marconi', 'disambig_question': 'What individual should be called the father of radio?', 'disambig_prompt_response': 'Guglielmo Marconi', 'ground_truth': ['Lee de Forest'], 'question_distance': 0.9767232029826212, 'answer_distance': 1.0000000000000018, 'ambig_answer_distance': 0.16036456469139476, 'disambig_answer_distance': 0.16035376381139022}\n",
      "What team has won the most Little League World Series?\n",
      "{'data_id': '3319993667507902552', 'ambig_question': 'Who has won the most little league world series?', 'ambig_prompt_response': 'Taiwan', 'disambig_question': 'What team has won the most Little League World Series?', 'disambig_prompt_response': 'Taiwan', 'ground_truth': ['Taiwan'], 'question_distance': 0.9549180531470096, 'answer_distance': 1.0000000000000002, 'ambig_answer_distance': 1.0000000000000002, 'disambig_answer_distance': 1.0000000000000002}\n",
      "On what river is the Sandhu Bat Island, where the Statue of Unity is to be built, located?\n",
      "{'data_id': '907287579079542483', 'ambig_question': 'The sandhu bat island on which the statue of unity is to be built is located on which river?', 'ambig_prompt_response': 'Narmada', 'disambig_question': 'On what river is the Sandhu Bat Island, where the Statue of Unity is to be built, located?', 'disambig_prompt_response': 'Narmada River', 'ground_truth': ['Narmada River'], 'question_distance': 0.937794829735396, 'answer_distance': 0.8150399792003982, 'ambig_answer_distance': 0.8150399792003982, 'disambig_answer_distance': 0.9999999999999996}\n",
      "====================\n",
      "Average ambig answer distance: 0.698107924786949\n",
      "Average disambig answer distance: 0.7330901923373037\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# go through sample.json and ask questions to gpt\n",
    "import json\n",
    "all_qs = json.load(open(\"filtered_train.json\"))\n",
    "\n",
    "# randomly sample 10 questions\n",
    "import random\n",
    "sample = random.sample(all_qs, 30)\n",
    "\n",
    "print(sample)\n",
    "\n",
    "output = []\n",
    "\n",
    "sum_1 = 0\n",
    "sum_2 = 0\n",
    "\n",
    "for i in sample:\n",
    "    # print(\"-\"*20)\n",
    "    ootb_llm_rseponse = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Answer the question as concisely as possible with ONLY one answer without any other text:  {i['nq_question']}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o\"\n",
    "    )\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Rewrite this question replacing all questions with a what, but retain the meaning by specifying what entity or what person or what timeframe the \\\"what\\\" answering. Also specify the year is 2018 is needed to answer a time-based question. The Question: {i['nq_question']}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "    final_answer = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Answer the question as concisely as possible with ONLY one answer without any other text:  {chat_completion.choices[0].message.content}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "\n",
    "    ambig_answer_distance = 0\n",
    "    disambig_answer_distance = 0\n",
    "    for ans in i[\"nq_answer\"]:\n",
    "        curr_ambig_answer_distance = get_distance(ans, ootb_llm_rseponse.choices[0].message.content)\n",
    "        curr_disambig_answer_distance = get_distance(ans, final_answer.choices[0].message.content)\n",
    "        if curr_ambig_answer_distance > ambig_answer_distance:\n",
    "            ambig_answer_distance = curr_ambig_answer_distance\n",
    "        if curr_disambig_answer_distance > disambig_answer_distance:\n",
    "            disambig_answer_distance = curr_disambig_answer_distance\n",
    "\n",
    "    curr = {\n",
    "        \"data_id\": i[\"nq_id\"],\n",
    "        \"ambig_question\": i[\"nq_question\"],\n",
    "        \"ambig_prompt_response\": ootb_llm_rseponse.choices[0].message.content,\n",
    "        \"disambig_question\": chat_completion.choices[0].message.content,\n",
    "        \"disambig_prompt_response\": final_answer.choices[0].message.content,\n",
    "        \"ground_truth\": i[\"nq_answer\"],\n",
    "        \"question_distance\": get_distance(i[\"nq_question\"], chat_completion.choices[0].message.content),\n",
    "        \"answer_distance\": get_distance(ootb_llm_rseponse.choices[0].message.content, final_answer.choices[0].message.content),\n",
    "        \"ambig_answer_distance\": ambig_answer_distance,\n",
    "        \"disambig_answer_distance\": disambig_answer_distance\n",
    "    }\n",
    "\n",
    "    sum_1 += curr[\"ambig_answer_distance\"]\n",
    "    sum_2 += curr[\"disambig_answer_distance\"]\n",
    "\n",
    "    # print(f\"question_distance: {get_distance(i[\"nq_question\"], chat_completion.choices[0].message.content)}\")\n",
    "    # print(f\"answer_distance: {get_distance(ootb_llm_rseponse.choices[0].message.content, final_answer.choices[0].message.content)}\")\n",
    "    # if i[\"nq_answer\"] is list:\n",
    "    # print(f\"ambig_answer_distance: {get_distance(i[\"nq_answer\"], ootb_llm_rseponse.choices[0].message.content)}\")\n",
    "    # print(f\"disambig_answer_distance: {get_distance(i[\"nq_answer\"], final_answer.choices[0].message.content)}\")\n",
    "\n",
    "    output.append(curr)\n",
    "\n",
    "    # save output to json file\n",
    "    json.dump(output, open(\"disambig_prompt.json\", \"w\"))\n",
    "\n",
    "    print(curr)\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(f\"Average ambig answer distance: {sum_1/len(sample)}\")\n",
    "print(f\"Average disambig answer distance: {sum_2/len(sample)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
