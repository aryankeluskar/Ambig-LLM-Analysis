{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # Ensure the vectors are numpy arrays\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    # Compute the dot product and magnitudes\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    magnitude = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "    \n",
    "    # Prevent division by zero\n",
    "    if magnitude == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dot_product / magnitude\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def get_distance(text1, text2, model=\"text-embedding-3-large\"):\n",
    "   text1 = str(text1).lower()\n",
    "   text2 = str(text2).lower()\n",
    "   embedding1 = get_embedding(text1, model)\n",
    "   embedding2 = get_embedding(text2, model)\n",
    "   return cosine_similarity(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0\n",
      "The Marvelettes\n",
      "The Marvelettes\n",
      "Processing 1\n",
      "Figaro\n",
      "Figaro\n",
      "Processing 2\n",
      "12 sacks.\n",
      "12 sacks.\n",
      "Processing 3\n",
      "New Year's Day\n",
      "2015\n",
      "Processing 4\n",
      "Monument Avenue in Richmond, VA, was previously known for its statues of Confederate figures and Arthur Ashe, though most Confederate statues were removed by 2021.\n",
      "Selena Gomez.\n",
      "Processing 5\n",
      "Mark Ruffalo.\n",
      "Mark Ruffalo\n",
      "Processing 6\n",
      "The moon's gravitational pull.\n",
      "Aaron Judge\n",
      "Processing 7\n",
      "16\n",
      "2017\n",
      "Processing 8\n",
      "\"Baby Shark Dance\" by Pinkfong.\n",
      "Atticus Finch\n",
      "Processing 9\n",
      "February 5, 2016.\n",
      "Patrick Bergin\n",
      "Average question distance: 0.9059289299755575\n",
      "Average answer distance: 0.49447405057584454\n",
      "Average ambig answer distance: 0.3811690162115744\n",
      "Average disambig answer distance: 0.8053376999332093\n"
     ]
    }
   ],
   "source": [
    "# load /Users/aryank/Developer/dmml-research/off-track exps/disambig_filter_with_our_sample.json into upper\n",
    "# load /Users/aryank/Developer/dmml-research/Experiments/o_sample_output_1729209119.json into baseline\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "baseline = json.load(open('/Users/aryank/Developer/dmml-research/Experiments/o_sample_output_1729209119.json'))[:10]\n",
    "upper = json.load(open('/Users/aryank/Developer/dmml-research/off-track exps/disambig_filter_with_our_sample.json'))[:10]\n",
    "\n",
    "# sort basline by data_id attribute\n",
    "baseline = sorted(baseline, key=lambda x: x['data_id'])\n",
    "\n",
    "# sort upper by nq_id attribute\n",
    "upper = sorted(upper, key=lambda x: x['nq_id'])\n",
    "\n",
    "sum_question_distance = 0\n",
    "sum_answer_distance = 0\n",
    "sum_ambig_answer_distance = 0\n",
    "sum_disambig_answer_distance = 0\n",
    "\n",
    "for i in range(len(baseline)):\n",
    "    print(f\"Processing {i}\")\n",
    "    print(baseline[i][\"llm_response\"])\n",
    "    print(upper[i][\"disambig_llm_answer\"])\n",
    "\n",
    "    ambig_answer_distance = 0\n",
    "    disambig_answer_distance = 0\n",
    "    for ans in upper[i][\"ground_truth\"]:\n",
    "        curr_ambig_answer_distance = get_distance(ans, baseline[i][\"llm_response\"])\n",
    "        # curr_disambig_answer_distance = get_distance(ans, upper[i][\"llm_response\"])\n",
    "        if curr_ambig_answer_distance > ambig_answer_distance:\n",
    "            ambig_answer_distance = curr_ambig_answer_distance\n",
    "        # if curr_disambig_answer_distance > disambig_answer_distance:\n",
    "        #     disambig_answer_distance = curr_disambig_answer_distance\n",
    "\n",
    "    sum_ambig_answer_distance += curr_ambig_answer_distance\n",
    "    sum_disambig_answer_distance += upper[i]['disambig_answer_distance']\n",
    "\n",
    "    sum_question_distance += upper[i]['question_distance']\n",
    "    sum_answer_distance += get_distance(baseline[i]['llm_response'], upper[i]['disambig_llm_answer'])\n",
    "\n",
    "print(f\"Average question distance: {sum_question_distance / len(baseline)}\")\n",
    "print(f\"Average answer distance: {sum_answer_distance / len(baseline)}\")\n",
    "print(f\"Average ambig answer distance: {sum_ambig_answer_distance / len(baseline)}\")\n",
    "print(f\"Average disambig answer distance: {sum_disambig_answer_distance / len(baseline)}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
